name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.10, 3.11]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Create necessary directories
      run: |
        mkdir -p data/sample logs models/checkpoints static/uploads

    - name: Lint with flake8
      run: |
        flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503

    - name: Check code formatting with black
      run: |
        black src/ tests/ --check --line-length=100

    - name: Check import sorting with isort
      run: |
        isort src/ tests/ --profile black --check-only

    - name: Type check with mypy
      run: |
        mypy src/ --ignore-missing-imports

    - name: Security check with bandit
      run: |
        bandit -r src/ -f json -o security-report.json
      continue-on-error: true

    - name: Run tests with pytest
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=term-missing

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload security report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-report-${{ matrix.python-version }}
        path: security-report.json

  docker-build:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Docker image
      run: |
        docker build -t xai-medical-images:test .

    - name: Test Docker image
      run: |
        docker run --rm -d --name test-container -p 5000:5000 xai-medical-images:test
        sleep 10
        curl -f http://localhost:5000/health || exit 1
        docker stop test-container

  integration-test:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Create test data
      run: |
        python scripts/download_sample_data.py --dataset synthetic --num_samples 10

    - name: Validate test data
      run: |
        python scripts/validate_data.py --data_dir data/sample

    - name: Run integration tests
      run: |
        python -m pytest tests/ -v -m "integration" --tb=short
      continue-on-error: true

  performance-test:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run performance benchmarks
      run: |
        python scripts/benchmark_model.py --output_file benchmark-results.json --inference_samples 20 --gradcam_samples 10

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark-results.json